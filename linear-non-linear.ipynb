{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear Non-Linear Functions\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preface\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Some modules we&rsquo;ll want:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\nfrom numpy.linalg import norm\nfrom scipy.stats import distributions as iid\nimport pandas as pd\nimport matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Factories to generate basis functions\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can use a collection of functions as a *basis* with which to represent\nan arbitrary function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Factory function for phi_k(x)\nphi_factory = lambda c,s=1: lambda x: np.exp(-(1/(2*s))*norm(x-c)**2)  # RBF\n# phi_factory = lambda c,s=1: lambda x: (x**c)/s  # Polynomial\n# phi_factory = lambda c,s=1: lambda x: 1/(1+np.exp(c-x))  # logistic\n\n# Also chose a domain over which we'll want to evaluate the unknown function\nDomain = np.linspace(0,2*np.pi,100).tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now use  this factory to generate a set of $K$ basis functions for our\nrepresentation:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Or\nK=18\n\n# Divide up domain\nphis = {k:phi_factory(Domain[x]) for k,x in enumerate(range(1,len(Domain),len(Domain)//K))}\n\n# Gram matrix if K=N\n#phis = {k:phi_factory(X[k]) for k in range(K)}\n\nphis[0] = lambda x: 1 # Constant function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the basis functions:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots()\nfor k in range(K):\n    ax.plot(Domain,[phis[k](x) for x in Domain])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data generating function\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let $f_0(X) = \\mbox{E}(y|X)$ be an arbitrary function.  \nAfter specifying this function we define a data data-generating\nfunction for $(X,y)$ satisfying $y=f_0(X) + u$ and $\\mbox{E}(u|X)=0$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "f0 = lambda x: x*np.sin(x) # True function; make up your own!\n\ndef dgp(N,sigma_u):\n    X = iid.uniform(loc=0,scale=2*np.pi).rvs(N).tolist()\n    X.sort()\n\n    u = iid.norm(scale=sigma_u)\n\n    y = pd.Series([f0(x) + u.rvs(1)[0] for x in X])\n\n    return X,y\n\nN = 20\nX,y = dgp(N,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consider scatterplot:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\n\nax.scatter(X,y)\n\nax.plot(Domain,[f0(x) for x in Domain])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Estimation\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now regression.  Suppose we don&rsquo;t know the true function `f0`, and\ncan only estimate using observed data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "TX = {}\nfor k in phis.keys():\n    TX[k] = [phis[k](x) for x in X]\n\nTX = pd.DataFrame(TX)\n\ntry: # If y isn't a DataFrame make it one\n    y = pd.DataFrame({'y':y})\nexcept ValueError: # Guess it is!\n    pass\n\nalpha = pd.DataFrame(np.linalg.lstsq(TX, y,rcond=None)[0],index=TX.columns)\n\n# Check fit:\ne = y.squeeze() - (TX@alpha).squeeze()\n\ne.var()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that expected *within* sample error variance is pretty small!\n\nNow construct $\\hat{f}$:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fhat(x,alpha):\n\n    try: # Make alpha 1-d for calculations here\n        alpha = alpha.squeeze()\n    except AttributeError: # Maybe a list?\n        pass\n    \n    yhat = 0\n    for k,phik in phis.items():\n        yhat += alpha[k]*phik(x)\n\n    return yhat\n\nDomain = np.linspace(0,2*np.pi,100).tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot me!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n\nax.scatter(X,y)\nax.plot(Domain,[f0(x) for x in Domain],'r')\n\n_ = ax.plot(Domain,[fhat(x,alpha) for x in Domain],'g')\nax.axis((0,2*np.pi,-8,8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluating Fit\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We&rsquo;d like a measure of how well we&rsquo;ve done in estimating the\nconditional expectation $f$.  First, compute the integrated mean squared error\n(IMSE).  Note that when we don&rsquo;t know the true function `f_0` that this\nis isn&rsquo;t feasible to compute.  Here we compute a sum of squared\nprediction errors as a crude way of computing the integral $$ \\int\n(f_0(x) - \\hat{f}(x))^2dx.  $$\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "dx = Domain[1]-Domain[0]\nIMSE = np.sum([((f0(x) - fhat(x,alpha))**2)*dx for x in Domain])\n\nIMSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that the disturbances $u$ don&rsquo;t\nenter here&#x2014;this is the integrated mean squared *approximation* error, not the\nexpecteed mean squared error of predictions of actual realizations of the data\n$(y,X)$.  If we wanted the latter we&rsquo;d compute\n$$\n   \\mbox{E}((y-\\hat{f}(X))^2) =  \\mbox{E}((y-f(X)-\\epsilon)^2) =\n\\mbox{E}u^2 + \\mbox{MSE}.\n$$\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Leave-one-out estimator\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We next estimate $f$ using the &ldquo;leave-one-out&rdquo; approach.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "def leave_one_out(y,X,phis):\n    \"\"\"\n    Construct \"leave-one-out\" cross-validation estimator.\n    \"\"\"\n    try: # If y isn't a DataFrame make it one\n        y = pd.DataFrame({'y':y})\n    except ValueError: # Guess it is!\n        pass\n\n    def fhat(x,alpha):\n        \"\"\"\n        Construct estimated function from parameters alpha.\n        \"\"\"\n        try: # Make alpha 1-d for calculations here\n            alpha = alpha.squeeze()\n        except AttributeError: # Maybe a list?\n           pass\n        yhat = 0\n        for k,phik in phis.items():\n            yhat += alpha[k]*phik(x)\n\n        return yhat\n\n    # Construct transformed data\n    TX = {}\n    for k in phis.keys():\n        TX[k] = [phis[k](x) for x in X]\n\n        TX = pd.DataFrame(TX)\n\n\n    # Calculate leave-out-one parameters\n    Yminus = []\n    CV = 0\n    for j in range(N):\n        alphaminus = pd.DataFrame(np.linalg.lstsq(TX[TX.index!=j],\n                                                  y[TX.index!=j],rcond=None)[0],index=TX.columns)\n\n        yminus = lambda x: fhat(x,alphaminus)\n        CV += (y.squeeze()[j] - yminus(X[j]))**2/N\n\n        Yminus.append(yminus)\n\n    yhat = lambda x: np.array([yminus(x) for yminus in Yminus]).mean()    \n\n    return yhat,CV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Take a look at $f$ and the leave-one-out estimator:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "yhat,CV = leave_one_out(y,X,phis)\n\nfig, ax = plt.subplots()\n\nax.scatter(X,y,label='Data')\n\nax.plot(Domain,[f0(x) for x in Domain],label='$f_0$')\n\nax.plot(Domain,[fhat(x,alpha) for x in Domain],label='$\\hat{f}$')\n\nax.plot(Domain,[yhat(x) for x in Domain],label='$\\hat{y}_{-}$')\nax.axis((0,2*np.pi,-8,8))\nax.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n\nax.plot(Domain,[yhat(x) - fhat(x,alpha) for x in Domain],label='$\\hat{y}(x) - \\hat{f}(x)$')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using CV criterion to &ldquo;tune&rdquo; $K$\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "def CV(K,X,y):\n    \"\"\"\n    Estimate relationship between y & X using basis of dimension K; return CV statistic.\n    \"\"\"\n    phis = {k:phi_factory(Domain[x]) for k,x in enumerate(range(1,len(Domain),len(Domain)//K))}\n\n    # Gram matrix if K=N\n    phis = {k:phi_factory(X[k]) for k in range(K)}\n    phis[K] = lambda x: 1 # Constant function\n\n    # Construct basis\n\n    yhat,cv = leave_one_out(y,X,phis)\n\n    return cv\n\nN = 100\nX,y = dgp(N,1)   # Draw new random sample\n\nCV(4,X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate CV for different values of $K$:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "Ks = range(1,50)\n\nfig, ax = plt.subplots()\n\nCVs = [CV(k,X,y) for k in Ks]\nax.plot(Ks,CVs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot using the &ldquo;optimal&rdquo; $K$:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "myK = np.argmin(CVs)\n\nphis = {k:phi_factory(X[k]) for k in range(myK)}\nphis[myK] = lambda x: 1 # Constant function\n\nyhat,cv = leave_one_out(y,X,phis)\n\nfig, ax = plt.subplots()\n\nax.scatter(X,y,label='Data')\n\nax.plot(Domain,[f0(x) for x in Domain],label='$f_0$')\n\nax.plot(Domain,[yhat(x) for x in Domain],label='$\\hat{y}_{-}$')\nax.axis((0,2*np.pi,-8,8))\nax.legend()"
      ]
    }
  ],
  "metadata": {
    "org": null,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
