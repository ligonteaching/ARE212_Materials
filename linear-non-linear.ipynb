{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Linear Non-Linear Functions\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Preface\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Some modules we&rsquo;ll want:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\nfrom numpy.linalg import norm\nfrom scipy.stats import distributions as iid\nimport pandas as pd\nimport matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{},"source":["### Factories to generate basis functions\n\n"]},{"cell_type":"markdown","metadata":{},"source":["We can use a collection of functions as a *basis* with which to represent\nan arbitrary function.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Factory function for phi_k(x)\nphi_factory = lambda c,s=1: lambda x: np.exp(-(1/(2*s))*norm(x-c)**2)  # RBF\n# phi_factory = lambda c,s=1: lambda x: (x**c)/s  # Polynomial\n# phi_factory = lambda c,s=1: lambda x: 1/(1+np.exp(c-x))  # logistic\n\n# Also chose a domain over which we'll want to evaluate the unknown function\nDomain = np.linspace(0,2*np.pi,100).tolist()"]},{"cell_type":"markdown","metadata":{},"source":["Now use  this factory to generate a set of $K$ basis functions for our\nrepresentation:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["## Or\nK=18\n\n# Divide up domain\nphis = {k:phi_factory(Domain[x]) for k,x in enumerate(range(1,len(Domain),len(Domain)//K))}\n\n# Gram matrix if K=N\n#phis = {k:phi_factory(X[k]) for k in range(K)}\n\nphis[0] = lambda x: 1 # Constant function"]},{"cell_type":"markdown","metadata":{},"source":["Plot the basis functions:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["for k in range(K):\n    plt.plot(Domain,[phis[k](x) for x in Domain])"]},{"cell_type":"markdown","metadata":{},"source":["### Data generating function\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Let $f_0(X) = \\mbox{E}(y|X)$ be an arbitrary function.\nAfter specifying this function we define a data data-generating\nfunction for $(X,y)$ satisfying $y=f_0(X) + u$ and $\\mbox{E}(u|X)=0$.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["f0 = lambda x: x*np.sin(x) # True function; make up your own!\n\ndef dgp(N,sigma_u):\n    X = iid.uniform(loc=0,scale=2*np.pi).rvs(N).tolist()\n    X.sort()\n\n    u = iid.norm(scale=sigma_u)\n\n    y = pd.Series([f0(x) + u.rvs(1)[0] for x in X])\n\n    return X,y\n\nN = 20\nX,y = dgp(N,1)"]},{"cell_type":"markdown","metadata":{},"source":["Consider scatterplot:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\n\nax.scatter(X,y)\n\nax.plot(Domain,[f0(x) for x in Domain])"]},{"cell_type":"markdown","metadata":{},"source":["### Estimation\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Now regression.  Suppose we don&rsquo;t know the true function `f0`, and\ncan only estimate using observed data.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["TX = {}\nfor k in phis.keys():\n    TX[k] = [phis[k](x) for x in X]\n\nTX = pd.DataFrame(TX)\n\ntry: # If y isn't a DataFrame make it one\n    y = pd.DataFrame({'y':y})\nexcept ValueError: # Guess it is!\n    pass\n\nalpha = pd.DataFrame(np.linalg.lstsq(TX, y,rcond=None)[0],index=TX.columns)\n\n# Check fit:\ne = y.squeeze() - (TX@alpha).squeeze()\n\ne.var()"]},{"cell_type":"markdown","metadata":{},"source":["Note that expected *within* sample error variance is pretty small!\n\nNow construct $\\hat{f}$ and plot predictions:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["def fhat(x,alpha):\n\n    try: # Make alpha 1-d for calculations here\n        alpha = alpha.squeeze()\n    except AttributeError: # Maybe a list?\n        pass\n\n    yhat = 0\n    for k,phik in phis.items():\n        yhat += alpha[k]*phik(x)\n\n    return yhat\n\nDomain = np.linspace(0,2*np.pi,100).tolist()"]},{"cell_type":"markdown","metadata":{},"source":["Plot me!\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["fig, ax = plt.subplots()\n\nax.plot(Domain,[f0(x) for x in Domain])\nax.scatter(X,y)\n\n_ = ax.plot(Domain,[fhat(x,alpha) for x in Domain])\nax.axis((0,2*np.pi,-8,8))"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluating Fit\n\n"]},{"cell_type":"markdown","metadata":{},"source":["We&rsquo;d like a measure of how well we&rsquo;ve done in estimating the\nconditional expectation $f$.  First, compute the integrated mean squared error\n(IMSE).  Note that when we don&rsquo;t know the true function `f_0` that this\nis isn&rsquo;t feasible to compute.  Here we compute a sum of squared\nprediction errors as a crude way of computing the integral $$ \\int\n(f_0(x) - \\hat{f}(x))^2dx.  $$\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["dx = Domain[1]-Domain[0]\nIMSE = np.sum([((f0(x) - fhat(x,alpha))**2)*dx for x in Domain])\n\nIMSE"]},{"cell_type":"markdown","metadata":{},"source":["Note that the disturbances $u$ don&rsquo;t\nenter here&#x2014;this is the integrated mean squared *approximation* error, not the\nexpecteed mean squared error of predictions of actual realizations of the data\n$(y,X)$.  If we wanted the latter we&rsquo;d compute\n$$\n   \\mbox{E}((y-\\hat{f}(X))^2) =  \\mbox{E}((y-f(X)-\\epsilon)^2) =\n\\mbox{E}u^2 + \\mbox{MSE}.\n$$\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Leave-one-out estimator\n\n"]},{"cell_type":"markdown","metadata":{},"source":["We next estimate $f$ using the &ldquo;leave-one-out&rdquo; approach.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["def leave_one_out(y,X,phis):\n    \"\"\"\n    Construct \"leave-one-out\" cross-validation estimator.\n    \"\"\"\n    try: # If y isn't a DataFrame make it one\n        y = pd.DataFrame({'y':y})\n    except ValueError: # Guess it is!\n        pass\n\n    def fhat(x,alpha):\n        \"\"\"\n        Construct estimated function from parameters alpha.\n        \"\"\"\n        try: # Make alpha 1-d for calculations here\n            alpha = alpha.squeeze()\n        except AttributeError: # Maybe a list?\n           pass\n        yhat = 0\n        for k,phik in phis.items():\n            yhat += alpha[k]*phik(x)\n\n        return yhat\n\n    # Construct transformed data\n    TX = {}\n    for k in phis.keys():\n        TX[k] = [phis[k](x) for x in X]\n\n        TX = pd.DataFrame(TX)\n\n\n    # Calculate leave-out-one parameters\n    Yminus = []\n    CV = 0\n    for j in range(N):\n        alphaminus = pd.DataFrame(np.linalg.lstsq(TX[TX.index!=j],\n                                                  y[TX.index!=j],rcond=None)[0],index=TX.columns)\n\n        yminus = lambda x: fhat(x,alphaminus)\n        CV += (y.squeeze()[j] - yminus(X[j]))**2/N\n\n        Yminus.append(yminus)\n\n    yhat = lambda x: np.array([yminus(x) for yminus in Yminus]).mean()\n\n    return yhat,CV"]},{"cell_type":"markdown","metadata":{},"source":["Take a look at $f$ and the leave-one-out estimator:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["yhat,CV = leave_one_out(y,X,phis)\n\nfig, ax = plt.subplots()\n\nax.scatter(X,y,label='Data')\n\nax.plot(Domain,[f0(x) for x in Domain],label='$f_0$')\n\nax.plot(Domain,[fhat(x,alpha) for x in Domain],label='$\\hat{f}$')\n\nax.plot(Domain,[yhat(x) for x in Domain],label='$\\hat{y}_{-}$')\nax.axis((0,2*np.pi,-8,8))\nax.legend()"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["fig, ax = plt.subplots()\n\nax.plot(Domain,[yhat(x) - fhat(x,alpha) for x in Domain],label='$\\hat{y}(x) - \\hat{f}(x)$')"]},{"cell_type":"markdown","metadata":{},"source":["### Using CV criterion to &ldquo;tune&rdquo; $K$\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["def CV(K,X,y):\n    \"\"\"\n    Estimate relationship between y & X using basis of dimension K; return CV statistic.\n    \"\"\"\n    phis = {k:phi_factory(Domain[x]) for k,x in enumerate(range(1,len(Domain),len(Domain)//K))}\n\n    # Gram matrix if K=N\n    phis = {k:phi_factory(X[k]) for k in range(K)}\n    phis[K] = lambda x: 1 # Constant function\n\n    # Construct basis\n\n    yhat,cv = leave_one_out(y,X,phis)\n\n    return cv\n\nN = 100\nX,y = dgp(N,1)   # Draw new random sample\n\nCV(4,X,y)"]},{"cell_type":"markdown","metadata":{},"source":["Evaluate CV for different values of $K$:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["Ks = range(1,50)\n\nfig, ax = plt.subplots()\n\nCVs = [CV(k,X,y) for k in Ks]\nax.plot(Ks,CVs)"]},{"cell_type":"markdown","metadata":{},"source":["Plot using the &ldquo;optimal&rdquo; $K$:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["myK = np.argmin(CVs)\n\nphis = {k:phi_factory(X[k]) for k in range(myK)}\nphis[myK] = lambda x: 1 # Constant function\n\nyhat,cv = leave_one_out(y,X,phis)\n\nfig, ax = plt.subplots()\n\nax.scatter(X,y,label='Data')\n\nax.plot(Domain,[f0(x) for x in Domain],label='$f_0$')\n\nax.plot(Domain,[yhat(x) for x in Domain],label='$\\hat{y}_{-}$')\nax.axis((0,2*np.pi,-8,8))\nax.legend()"]}],"metadata":{"org":null,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}
